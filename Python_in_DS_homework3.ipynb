{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python для DataScience\n",
    "## Домашнее задание по уроку 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1\n",
    "Импортируйте библиотеки pandas и numpy. Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. <br/>\n",
    "Создайте датафреймы X и y из этих данных. Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42. <br/> \n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model. <br/> \n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.  <br/>\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение\n",
    "Импортируем модули pandas & numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет \"Boston House Prices dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "y = pd.DataFrame(boston['target'], columns=[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем датафреймы на тренировочные и проверочные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель линейной регрессии под названием `lr` с помощью класса `LinearRegression` из модуля `sklearn.linear_model`. Обучим модель на датасетах `X_train`, `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предсказание на тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним предсказанное с реальным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>28.648960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.495014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.411193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.403213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.855280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>20.0</td>\n",
       "      <td>23.146689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>17.8</td>\n",
       "      <td>17.392124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.078599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>19.6</td>\n",
       "      <td>23.036927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>16.8</td>\n",
       "      <td>20.599433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test    predict\n",
       "173  23.6  28.648960\n",
       "274  32.4  36.495014\n",
       "491  13.6  15.411193\n",
       "72   22.8  25.403213\n",
       "452  16.1  18.855280\n",
       "76   20.0  23.146689\n",
       "316  17.8  17.392124\n",
       "140  14.0  14.078599\n",
       "471  19.6  23.036927\n",
       "500  16.8  20.599433"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'test': y_test[\"price\"],\n",
    "    'predict': y_pred.flatten()\n",
    "}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим R2 полученных предказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711226005748496"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble. <br/>\n",
    "Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42.<br/>\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy, так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.<br/>\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.<br/>\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности, установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 4. В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection. Для этого датасета мы будем решать задачу классификации — определять, какие из транзакциции по кредитной карте являются мошенническими.\n",
    "Данный датасет несбалансирован (так как случаи мошенничества относительно редки), так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.\n",
    "Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split. Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.\n",
    "Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.\n",
    "Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма: pd.options.display.max_columns = 100.\n",
    "\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме.\n",
    "\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba.\n",
    "\n",
    "Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,\n",
    "полученным на тренировочных данных, используя в качестве аргументов\n",
    "массивы y_test и y_pred_proba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Дополнительные задания:\n",
    "1. Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data.\n",
    "2. Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. Просмотрите тип данных этой структуры данных и создайте список data_keys, содержащий ее ключи.\n",
    "3. Просмотрите данные, описание и названия признаков в датасете. Описание нужно вывести в виде привычного, аккуратно оформленного текста, без обозначений переноса строки, но с самими переносами и т. д.\n",
    "4. Сколько классов содержит целевая переменная датасета? Выведите названия классов.\n",
    "5. На основе данных датасета (они содержатся в двумерном массиве Numpy) и названий признаков создайте датафрейм под названием X.\n",
    "6. Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения.\n",
    "7. Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. Название поля - 'target'.\n",
    "8. Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr.\n",
    "9. Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному значению превышает 0.5 (причем, само поле target не должно входить в этот список).\n",
    "10. Удалите из датафрейма X поле с целевой переменной. Для всех признаков, названия которых содержатся в списке high_corr, вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', добавленного к первоначальному названию признака. Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, а также поля с признаками из списка high_corr, возведенными в квадрат. Выведите описание полей датафрейма X с помощью метода describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
